{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Vivli AMR Challenge - Data Processing**\n"
      ],
      "metadata": {
        "id": "gzr3oOyDkbVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Packages (Uncomment if needed)"
      ],
      "metadata": {
        "id": "P74uTCZ8ke-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGO3pNlxjInq"
      },
      "outputs": [],
      "source": [
        "!pip install econml scikit-learn pandas matplotlib seaborn dowhy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "atQcgJ5bklLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from econml.dml import CausalForestDML\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from dowhy import CausalModel\n",
        "from econml.dml import LinearDML, CausalForestDML,NonParamDML,DML\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from econml.score import RScorer"
      ],
      "metadata": {
        "id": "ky4np6MYkll2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "K4bZ4z18kyU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/') # Mounting Drive\n",
        "os.chdir('/content/drive/My Drive/AMR Challenge') # Changing Directory"
      ],
      "metadata": {
        "id": "TwgdTASHkyrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data"
      ],
      "metadata": {
        "id": "2PJZ6McIk3mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"2025_03_11 atlas_antibiotics.xlsx\")\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "_mb3-ksSk4Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Consider Meropenem Resistance\n",
        "*   Consider Enterobacterales\n",
        "\n"
      ],
      "metadata": {
        "id": "cof5AqfslGwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df[['Species','Family','Country','Gender','Age Group','Speciality','Source','In / Out Patient','Year','Meropenem','Meropenem_I']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "recnNh3WlTPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ent = df2[df2['Family'] == 'Enterobacteriaceae']\n",
        "df_ent.head(5)\n",
        "\n",
        "df_ent[\"MEM_resistant\"] = df_ent['Meropenem_I'].apply(\n",
        "    lambda x: 1 if pd.notna(x) and x == 'Resistant' else 0\n",
        ")\n",
        "\n",
        "# Encode Categorical Variables\n",
        "# Define covariates\n",
        "categorical_cols = ['Source', 'Age Group','Speciality', 'In / Out Patient']\n",
        "\n",
        "# One-hot encode\n",
        "df_ent = pd.get_dummies(df_ent, columns=categorical_cols, drop_first=True)\n",
        "df_ent = df_ent.drop(columns=['Family','Meropenem','Meropenem_I'],axis =1 )\n",
        "\n"
      ],
      "metadata": {
        "id": "3pEBlsiIlcbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Policy was enacted in 2015 in Greece"
      ],
      "metadata": {
        "id": "ICEWLNtXlvk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gr = df_ent[df_ent['Country'] == 'Greece'].drop(['Country','Species'],axis =1)\n",
        "\n",
        "binary_cols = df_gr.columns.difference([\"Year\", \"MEM_resistant\",'Gender'], sort=False)\n",
        "df_sum =(df_gr.groupby([\"Year\"])\n",
        "      .agg(\n",
        "          MEM_resistance_rate=(\"MEM_resistant\", \"mean\"),\n",
        "        **{col: (col, \"sum\") for col in binary_cols},\n",
        "        male_ratio=(\"Gender\", lambda x: np.mean(x == \"Male\"))\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "df_sum['policy'] = (df_sum['Year'] >= 2015).astype(int)"
      ],
      "metadata": {
        "id": "DzVINgOLl3bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df_sum['MEM_resistance_rate']\n",
        "T = df_sum['policy']\n",
        "X = df_sum[[col for col in df_sum.columns if col not in ['MEM_resistance_rate', 'policy', 'Year']]]"
      ],
      "metadata": {
        "id": "O-BRbuRAmD7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Development"
      ],
      "metadata": {
        "id": "sZm7oTibmZSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs_outcome = [\n",
        "    {\n",
        "        'name': 'RandomForest',\n",
        "        'estimator': RandomForestRegressor(random_state=0),\n",
        "        'param_grid': {\n",
        "            'n_estimators':    (10, 30, 50, 100, 200),\n",
        "            'max_depth':       [3, 5, None]\n",
        "          #  'model__min_samples_leaf':[1, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'GradientBoosting',\n",
        "        'estimator': GradientBoostingRegressor(random_state=0),\n",
        "        'param_grid': {\n",
        "            'n_estimators':    (50, 100, 200),\n",
        "            'max_depth':       [3, 5,None],\n",
        "            'learning_rate':   [0.1, 0.05]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'LassoCV',\n",
        "        'estimator': LassoCV(cv=5, random_state=0),\n",
        "        'param_grid': {}  # LassoCV does its own CV over alphas\n",
        "    }\n",
        "]\n",
        "\n",
        "model_configs_treatment = [\n",
        "    {\n",
        "        'name': 'RandomForest',\n",
        "        'estimator': RandomForestClassifier(random_state=0),\n",
        "        'param_grid': {\n",
        "            'n_estimators':    (10, 30, 50, 100, 200),\n",
        "            'max_depth':       [3, 5, None]\n",
        "          #  'model__min_samples_leaf':[1, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'GradientBoosting',\n",
        "        'estimator': GradientBoostingClassifier(random_state=0),\n",
        "        'param_grid': {\n",
        "            'n_estimators':    (50, 100, 200),\n",
        "            'max_depth':       [3, 5,None],\n",
        "            'learning_rate':   [0.1, 0.05]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'LassoCV',\n",
        "        'estimator': LassoCV(cv=5, random_state=0),\n",
        "        'param_grid': {}  # LassoCV does its own CV over alphas\n",
        "    }\n",
        "]\n",
        "\n",
        "# Loop, fit GridSearchCV, collect results\n",
        "results_treatment = []\n",
        "for cfg in model_configs_outcome:\n",
        "    gs = GridSearchCV(\n",
        "        estimator=cfg['estimator'],\n",
        "        param_grid=cfg['param_grid'],\n",
        "        scoring='neg_mean_squared_error',\n",
        "        cv=10,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    print(f\"â†’ Tuning {cfg['name']}...\")\n",
        "    gs.fit(X, T)\n",
        "    results_treatment.append({\n",
        "        'name':         cfg['name'],\n",
        "        'best_score':   gs.best_score_,\n",
        "        'best_params':  gs.best_params_,\n",
        "       'best_estimator': gs.best_estimator_\n",
        "    })\n",
        "\n",
        "\n",
        "results_outcome = []\n",
        "for cfg in model_configs_treatment:\n",
        "    gs = GridSearchCV(\n",
        "        estimator=cfg['estimator'],\n",
        "        param_grid=cfg['param_grid'],\n",
        "        scoring='neg_mean_squared_error',\n",
        "        cv=10,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    print(f\"â†’ Tuning {cfg['name']}...\")\n",
        "    gs.fit(X, Y)\n",
        "    results_outcome.append({\n",
        "        'name':         cfg['name'],\n",
        "        'best_score':   gs.best_score_,\n",
        "        'best_params':  gs.best_params_,\n",
        "       'best_estimator': gs.best_estimator_\n",
        "    })"
      ],
      "metadata": {
        "id": "ZD0pPBz8maa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Find & store the best outcome model\n",
        "best_outcome = max(results_outcome, key=lambda r: r['best_score'])\n",
        "best_outcome_name   = best_outcome['name']\n",
        "best_outcome_score  = best_outcome['best_score']\n",
        "best_outcome_params = best_outcome['best_params']\n",
        "best_model_y        = best_outcome['best_estimator']\n",
        "\n",
        "#Find & store the best treatment model\n",
        "best_treatment = max(results_treatment, key=lambda r: r['best_score'])\n",
        "best_treatment_name   = best_treatment['name']\n",
        "best_treatment_score  = best_treatment['best_score']\n",
        "best_treatment_params = best_treatment['best_params']\n",
        "best_model_t          = best_treatment['best_estimator']\n",
        "\n",
        "#Print a summary (or use in fâ€‘strings later)\n",
        "print(f\"ðŸ† Best Outcome Model  : {best_outcome_name}\")\n",
        "print(f\"   â€¢ negâ€‘MSE        = {best_outcome_score:.4f}\")\n",
        "print(f\"   â€¢ params         = {best_outcome_params}\\n\")\n",
        "\n",
        "print(f\"ðŸ† Best Treatment Model: {best_treatment_name}\")\n",
        "print(f\"   â€¢ score (AUC or negâ€‘MSE) = {best_treatment_score:.4f}\")\n",
        "print(f\"   â€¢ params                = {best_treatment_params}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "42aY9OgXm2W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data in train-validation\n",
        "X_train, X_val, T_train, T_val, Y_train, Y_val = train_test_split(X, T, Y, test_size=.4)"
      ],
      "metadata": {
        "id": "o8-KK1LYnHVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_estimator = CausalForestDML(\n",
        "    model_t=best_model_t,\n",
        "    model_y=best_model_y,\n",
        "    discrete_treatment=True,\n",
        "    n_estimators=200,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "\n",
        "cf_dw = cf_estimator.dowhy.fit(\n",
        "    Y_train,\n",
        "    T_train,\n",
        "    X_train)"
      ],
      "metadata": {
        "id": "QB2m6ivcnLZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refutation Test"
      ],
      "metadata": {
        "id": "Hu4ZYDk9nlnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cf_dw.refute_estimate(method_name=\"random_common_cause\"))\n",
        "print(cf_dw.refute_estimate(method_name=\"placebo_treatment_refuter\", placebo_type=\"permute\"))\n",
        "print(cf_dw.refute_estimate(method_name=\"data_subset_refuter\"))"
      ],
      "metadata": {
        "id": "cZXtgWacnlA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimate effect"
      ],
      "metadata": {
        "id": "yb_1PkuDnyww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sum['tau_hat'] = cf_dw.effect(X_val)"
      ],
      "metadata": {
        "id": "_odB_U0fnxzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "89ua1ixkoCfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sum['resistance_cf'] = df_sum['MEM_resistance_rate'] + df_sum['policy']*df_sum['tau_hat']\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(df_sum['Year'], df_sum['MEM_resistance_rate'], 'o-', label='Observed Resistance')\n",
        "plt.plot(df_sum['Year'], df_sum['resistance_cf'], 's--', label='Simulated (No Policy)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Resistance Rate (%)')\n",
        "plt.title('Observed vs Counterfactual Resistance\\n(What if Policy Had Not Been Enacted?)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_GT7odi0oD3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sum['Y0_hat'] = df_sum['MEM_resistance_rate'] - df_sum['policy'] * df_sum['tau_hat']\n",
        "\n",
        "# Scenario A: never roll it out\n",
        "df_sum['policy_never'] = 0\n",
        "df_sum['resistance_never'] = df_sum['Y0_hat']  # always Y(0)\n",
        "\n",
        "# Scenario B: roll out in 2012\n",
        "early_year = 2012\n",
        "df_sum['policy_2012'] = (df_sum['Year'] >= early_year).astype(int)\n",
        "df_sum['resistance_2012'] = df_sum['Y0_hat'] + df_sum['policy_2012'] * df_sum['tau_hat']\n",
        "\n",
        "# Aggregate all 4 curves\n",
        "agg = df_sum.groupby('Year').agg({\n",
        "    'MEM_resistance_rate':      'mean',\n",
        "    'resistance_cf':   'mean',  # = rolled out in 2015?  (same as observed minus orig effect)\n",
        "    'resistance_never':'mean',\n",
        "    'resistance_2012': 'mean'\n",
        "}).reset_index().rename(columns={\n",
        "    'MEM_resistance_rate':      'Observed',\n",
        "    'resistance_cf':   'Rollout=2015',\n",
        "    'resistance_never':'Rollout=None',\n",
        "    'resistance_2012': 'Rollout=2012'\n",
        "})\n",
        "\n",
        "#Plot\n",
        "plt.figure(figsize=(8,4))\n",
        "for col, style in [\n",
        "    ('Observed',      'o-'),\n",
        "    ('Rollout=None',  's--'),\n",
        "   # ('Rollout=2015',  'd:'),\n",
        "    ('Rollout=2012',  'x-.'),\n",
        "]:\n",
        "    plt.plot(agg['Year'], agg[col], style, label=col)\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Resistance (%)')\n",
        "plt.title('Observed vs. Counterfactual Rollout Scenarios')\n",
        "plt.axvline(2015, color=\"blue\", linestyle=\"--\", alpha=0.6, label=\"Policy Enacted 2015\")\n",
        "plt.axvline(2012, color=\"red\", linestyle=\"--\", alpha=0.6, label=\"Policy Enacted 2012\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.xticks(df_sum['Year'].unique(), rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h1NdtIQOoTHm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}